# Use AI responsibly with Azure AI Content Safety

https://learn.microsoft.com/en-us/training/modules/responsible-content-safety/

Azure AI Content Safety is a comprehensive tool designed to **detect and manage harmful content** in both user-generated and AI-generated materials. Learn how Azure AI Content Safety uses text and image APIs to help **identify and filter out content related to violence, hate, sexual content, and self-harm**.

## Learning objectives
By the end of this module, you'll be able to:

- Describe Azure AI Content Safety.
- Describe how Azure AI Content Safety operates.
- Describe when to use Azure AI Content Safety.

---

## Introduction

The amount of user-generated content being posted online is growing rapidly. We are also increasingly aware of the need to protect everyone from inappropriate or harmful content.

**Azure AI Content Safety is an AI service designed to help developers include advanced content safety into their applications and services.**

The challenges in maintaining safe and respectful online spaces are growing for developer teams responsible for hosting online discussions. Azure AI Content Safety identifies potentially unsafe content and helps organizations to comply with regulations and meet their own quality standards.

The need for improving online content safety has four main drivers:

- **Increase in harmful content**: There's been a huge growth in user-generated online content, including harmful and inappropriate content.
- **Regulatory pressures**: Government pressure to regulate online content.
- **Transparency**: Users need transparency in content moderation standards and enforcement.
- **Complex content**: Advances in technology are making it easier for users to post multimodal content and videos.

Note: Azure AI Content Safety replaces Azure Content Moderator, which was deprecated in February 2024 and will be retired by February 2027.

In this module, you'll learn about the key features of Azure AI Content Safety, and when each might be used.

---

## What is Content Safety

Azure AI Content Safety is a set of advanced content moderating features that can be incorporated into your applications and services. Azure AI Content Safety is available as a resource in the Azure portal.

Online content safeguarding is needed in a growing number of situations. Not only are we concerned with moderating content generated by people, but must also guard against the malicious use of AI.

### Trusting user-generated content

Social interaction is increasingly a part of many digital spaces. Genuine user-generated content is seen as independent and trustworthy, and used alongside advertising and marketing. Different industries are encouraging their customers to connect with each other and their brand.

Harmful content has many negative effects. It damages trusted brands, discourages users from participating in online forums, and can have a devastating impact on individuals.

**Azure AI Content Safety is designed to be used in applications and services to protect against harmful user-generated and AI-generated content.**

### Content Safety in Azure AI Foundry

Azure [AI Content Safety](https://ai.azure.com/explore/contentsafety) is available as part of Azure AI Foundry, a unified platform that enables you to explore many different Azure AI services, including Content Safety.

From the Azure AI Foundry home page, scroll down and select Explore Azure AI Services. From here, you can explore Content Safety by selecting View all Content Safety capabilities.

**Azure AI Content Safety Studio** enables you to explore and test Content Safety features for yourself. Select the feature you want to try, and then select Try it out. You can then use the user interface to test samples or your own material. Select View code to generate sample code in C#, Java, or Python. You can then copy and paste the sample code and amend the variables to use your own data.

---

## How does Azure AI Content Safety work?

**Azure AI Content Safety works with text and images, and AI-generated content.**

Content Safety vision capabilities are powered by Microsoft's Florence foundation model, which has been trained with billions of text-image pairs. Text analysis uses natural language processing techniques, giving a better understanding of nuance and context. Azure AI Content Safety is multilingual and can detect harmful content in both short form and long form. It's currently available in English, German, Spanish, French, Portuguese, Italian, and Chinese.

Azure AI Content Safety classifies content into four categories:

- Hate
- Sexual
- Self-harm
- Violence

A severity level for each category is used to determine whether content should be blocked, sent to a moderator, or auto approved.

Azure AI Content Safety features include:

### Safeguarding text content

