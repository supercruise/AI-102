# Build a conversational language understanding model

The Azure AI Language **conversational language understanding service (CLU)** enables you to train a model that apps can use to extract meaning from natural language.

## Learning objectives
After completing this module, you'll be able to:

- Provision Azure resources for Azure AI Language resource
- Define intents, utterances, and entities
- Use patterns to differentiate similar utterances
- Use pre-built entity components
- Train, test, publish, and review an Azure AI Language model

---

## Introduction

[Video](https://share.vidyard.com/watch/XYUdrPj43e5HhMYB6PRFVP?)

**Natural language processing (NLP)** is a common AI problem in which software must be able to work with text or speech in the natural language form that a human user would write or speak. Within the broader area of NLP, **natural language understanding (NLU)** deals with the problem of determining semantic meaning from natural language - usually by using a trained language model.

A common design pattern for a natural language understanding solution looks like this:

![pattern](https://learn.microsoft.com/en-us/training/wwl-data-ai/build-language-understanding-model/media/language-understanding-app.png)

In this design pattern:

1. An app accepts natural language input from a user.
2. A language model is used to determine semantic meaning (the user's intent).
3. The app performs an appropriate action.

**Azure AI Language** enables developers to build apps based on language models that can be trained with a relatively small number of samples to discern a user's intended meaning.

In this module, you'll learn how to use the service to create a natural language understanding app using Azure AI Language.

After completing this module, youâ€™ll be able to:

- Provision an Azure AI Language resource.
- Define intents, entities, and utterances.
- Use patterns to differentiate similar utterances.
- Use pre-built entity components.
- Train, test, publish, and review a model.

---

## Understand prebuilt capabilities of the Azure AI Language service

The Azure AI Language service provides various features for understanding human language. You can use each feature to better communicate with users, better understand incoming communication, or use them together to provide more insight into what the user is saying, intending, and asking about.

Azure AI Language service features fall into two categories: **Pre-configured features, and Learned features**. Learned features require building and training a model to correctly predict appropriate labels, which is covered in upcoming units of this module.

This unit covers most of the capabilities of the Azure AI Language service, but head over to the [Azure AI Language service documentation](https://learn.microsoft.com/en-us/azure/cognitive-services/language-service/overview) for a full list, including quickstarts and a full explanation of everything available.

Using these features in your app requires sending your query to the appropriate endpoint. The endpoint used to query a specific feature varies, but all of them are prefixed with the Azure AI Language resource you created in your Azure account, either when building your REST request or defining your client using an SDK. Examples of each can be found in the next unit.

## Pre-configured features

The Azure AI Language service provides certain features without any model labeling or training. Once you create your resource, you can send your data and use the returned results within your app.

The following features are all pre-configured.

### Summarization
Summarization is available for both documents and conversations, and will summarize the text into key sentences that are predicted to encapsulate the input's meaning.

### Named entity recognition
Named entity recognition can **extract and identify entities, such as people, places, or companies**, allowing your app to recognize different types of entities for improved natural language responses. For example, given the text "The waterfront pier is my favorite Seattle attraction", Seattle would be identified and categorized as a location.

### Personally identifiable information (PII) detection
PII detection allows you to **identify, categorize, and redact information that could be considered sensitive**, such as email addresses, home addresses, IP addresses, names, and protected health information. For example, if the text "email@contoso.com" was included in the query, the entire email address can be identified and redacted.

### Key phrase extraction
Key phrase extraction is a feature that quickly pulls the main concepts out of the provided text. For example, given the text "Text Analytics is one of the features in Azure AI Services.", the service would extract "Azure AI Services" and "Text Analytics".

### Sentiment analysis
Sentiment analysis identifies how **positive or negative** a string or document is. For example, given the text "Great hotel. Close to plenty of food and attractions we could walk to", the service would identify that as positive with a relatively high confidence score.

### Language detection
Language detection takes one or more documents, and identifies the language for each. For example, if the text of one of the documents was "Bonjour", the service would identify that as French.

## Learned features

Learned features require you to label data, train, and deploy your model to make it available to use in your application. These features allow you to customize what information is predicted or extracted.

> Note: Quality of data greatly impacts the model's accuracy. Be intentional about what data is used, how well it is tagged or labeled, and how varied the training data is. For details, see recommendations for labeling data, which includes valuable guidelines for tagging data. Also see the evaluation metrics that can assist in learning where your model needs improvement.

### Conversational language understanding (CLU)
CLU is one of the core custom features offered by Azure AI Language. CLU helps users to build **custom natural language understanding models to predict overall intent and extract important information from incoming utterances**. CLU does require data to be tagged by the user to teach it how to predict intents and entities accurately.

*The exercise in this module will be building a CLU model and using it in your app.*

### Custom named entity recognition
Custom entity recognition takes custom labeled data and extracts specified entities from unstructured text. For example, if you have various contract documents that you want to extract involved parties from, you can train a model to recognize how to predict them.

### Custom text classification
Custom text classification enables users to classify text or documents as custom defined groups. For example, you can train a model to look at news articles and identify the category they should fall into, such as News or Entertainment.

### Question answering
Question answering is a mostly pre-configured feature that provides answers to questions provided as input. The data to answer these questions comes from documents like FAQs or manuals.

For example, say you want to make a virtual chat assistant on your company website to answer common questions. You could use a company FAQ as the input document to create the question and answer pairs. Once deployed, your chat assistant can pass input questions to the service, and get the answers as a result.

For a complete list of capabilities and how to use them, see the [Azure AI Language documentation](https://learn.microsoft.com/en-us/azure/ai-services/language-service/overview).

---

## [Understand resources for building a conversational language understanding model](https://learn.microsoft.com/en-us/training/modules/build-language-understanding-model/2-understand-resources-for-building)

To use the Language Understanding service to develop a NLP solution, you'll need to **create a Language resource in Azure**. That resource will be used for both authoring your model and processing prediction requests from client applications.

> Tip: This module's lab covers building a model for conversational language understanding. For more focused modules on custom text classification and custom named entity recognition, see the custom solution modules in the [Develop natural language solutions](https://learn.microsoft.com/en-us/training/paths/develop-language-solutions-azure-ai) learning path.

### Build your model

For features that require a model for prediction, you'll need to build, train and deploy that model before using it to make a prediction. This building and training will teach the Azure AI Language service what to look for.

First, you'll need to create your Azure AI Language resource in the [Azure portal](https://portal.azure.com/). Then:

1. Search for **Azure AI services**.
2. Find and select **Language Service**.
3. Select *Create* under the **Language Service**.
4. Fill out the necessary details, choosing the region closest to you geographically (for best performance) and giving it a unique name.

Once that resource has been created, you'll need a key and the endpoint. You can find that on the left side under Keys and Endpoint of the resource overview page.

#### Use Language Studio

For a more visual method of building, training, and deploying your model, you can use [Language Studio](https://aka.ms/languageStudio) to achieve each of these steps. On the main page, you can choose to create a Conversational language understanding project. Once the project is created, then go through the same process as above to build, train, and deploy your model.

The lab in this module will walk through using Language Studio to build your model. If you'd like to learn more, see the [Language Studio quickstart](https://learn.microsoft.com/en-us/azure/ai-services/language-service/language-studio).

#### Use the REST API

One way to build your model is through the REST API. The pattern would be to create your project, import data, train, deploy, then use your model.

These tasks are done asynchronously; you'll need to submit a request to the appropriate URI for each step, and then send another request to get the status of that job.

For example, if you want to deploy a model for a conversational language understanding project, you'd submit the deployment job, and then check on the deployment job status.

##### Authentication

For each call to your Azure AI Language resource, you authenticate the request by providing the following header.

| Key | Value | 
| -- | -- |
| Ocp-Apim-Subscription-Key | The key to your resource |

##### Request deployment

Submit a POST request to the following endpoint.

`{ENDPOINT}/language/authoring/analyze-conversations/projects/{PROJECT-NAME}/deployments/{DEPLOYMENT-NAME}?api-version={API-VERSION}`

| Placeholder | Value | Example |
| -- | -- | -- |
| `{ENDPOINT}` | The endpoint of your Azure AI Language resource | `https://<your-subdomain>.cognitiveservices.azure.com` |
| `{PROJECT-NAME}` | The name for your project. This value is case-sensitive | `myProject` |
| `{DEPLOYMENT-NAME}` | The name for your deployment. This value is case-sensitive | `staging` |
| `{API-VERSION}` | The version of the API you're calling | `2022-05-01` |

Include the following `body` with your request.

Successfully submitting your request will receive a 202 response, with a response header of operation-location. This header will have a URL with which to request the status, formatted like this:

